[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "",
    "text": "This lab will walk us through some basic statistical tests in R, including chi-square, t-tests, and correlation tests. We will use data from the Long-Term Ecological Research (LTER) Network, which is a collaborative effort involving more than 2000 scientists and students investigating ecological processes over long temporal and broad spatial scales. The basics of this lab were adopted from a previous version of this course. This qmd for this lab can be downloaded here. Please download it into the repo of your choice and open it in RStudio to work through this lab:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#explore-the-dataset",
    "href": "index.html#explore-the-dataset",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "Explore the dataset",
    "text": "Explore the dataset\nTo start, we’ll begin looking at the and_vertebrates dataset. Start this section with some EDA to understand its structure, variables and data types:\n\n\nCode\n# Viewing the data structure:\nglimpse(data)\n\n\nRows: 32,209\nColumns: 16\n$ year        &lt;dbl&gt; 1987, 1987, 1987, 1987, 1987, 1987, 1987, 1987, 1987, 1987…\n$ sitecode    &lt;chr&gt; \"MACKCC-L\", \"MACKCC-L\", \"MACKCC-L\", \"MACKCC-L\", \"MACKCC-L\"…\n$ section     &lt;chr&gt; \"CC\", \"CC\", \"CC\", \"CC\", \"CC\", \"CC\", \"CC\", \"CC\", \"CC\", \"CC\"…\n$ reach       &lt;chr&gt; \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\"…\n$ pass        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ unitnum     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2…\n$ unittype    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\"…\n$ vert_index  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1, …\n$ pitnumber   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ species     &lt;chr&gt; \"Cutthroat trout\", \"Cutthroat trout\", \"Cutthroat trout\", \"…\n$ length_1_mm &lt;dbl&gt; 58, 61, 89, 58, 93, 86, 107, 131, 103, 117, 100, 127, 99, …\n$ length_2_mm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ weight_g    &lt;dbl&gt; 1.75, 1.95, 5.60, 2.15, 6.90, 5.90, 10.50, 20.60, 9.55, 13…\n$ clip        &lt;chr&gt; \"NONE\", \"NONE\", \"NONE\", \"NONE\", \"NONE\", \"NONE\", \"NONE\", \"N…\n$ sampledate  &lt;date&gt; 1987-10-07, 1987-10-07, 1987-10-07, 1987-10-07, 1987-10-0…\n$ notes       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nCode\nvis_dat(data)\n\n\n\n\n\n\n\n\n\nCode\n# Exploring the metadata with the Help tab:\n#?and_vertebrates\n\n\nThe data presented in this study shows an aquatic vertebrate population study of Cutthroat trout and the Cascade Torrent salamander and Coastal Giant salamanders within the clear cut or old growth coniferous forests of the Mack Creek. This was presented in Andrew’s Experimental Forest located in Oregon, measuring the lengths and weights of each observed from 1987 to 2019.\nThe data also contains 32,209 observations that were measured with 16 variables: year (of observation), sitecode (sample area), section (CC = clear cut forest; OG = upstream old growth), reach (L = lower reach [0-50 meters]; M = middle reach [50-100 meters]; U = upper reach [100-150 meters]), pass (binary [1/2], electroshocking pass number), unitnum (channel unit number), unitype (C = cascade; I = riffle; IP = isolated pool; P = pool; R = rapid; S = small fall/step; SC = side channel; NA = not sampled by unit), vert_index (unique code for each vertebrate), pitnumber (tag number for each vertebrate), species (name of species), length_1_mm (vertebrate length in millimeters [otal or snout-fork length for trout, and snout-vent length for salamanders]), length_2_mm (snout-tail length in millimeters [for Coastal giant salamander only]), weight_g (mass in grams), clip (LV = left ventral fin; LVRV = left and right ventral fins; RV = right ventral fin; NONE = no ventral fin clip), sampledata (date of observation), notes (any additional comments)."
  },
  {
    "objectID": "index.html#chi-square---categorical-analysis",
    "href": "index.html#chi-square---categorical-analysis",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "Chi-square - Categorical Analysis",
    "text": "Chi-square - Categorical Analysis\nWhen you are working with two categorical variables, the statistical test you use is a Chi-square test. This test helps identify a relationship between your two categorical variables.\nFor example, we have two categorical variables in the and_vertebrates data set:\n\nsection = two forest sections, clear cut (CC) and old growth (OG)\nunittype = stream channel unit classification type (C = cascade, I = riffle, IP = isolated pool (not connected to channel), P = pool, R = rapid, S = step (small falls), SC = side channel, NA = not sampled by unit)\n\nLets focus this question on Cutthroat trout. First explore the abundance of cutthroat trout in different channel types, using the count() function to return the total count/number of observations in each group - making sure to limit your analysis to “Cutthroat trout”.\n\n\nCode\ndata |&gt; \n  filter(species == \"Cutthroat trout\") |&gt;\n  count(unittype)\n\n\n# A tibble: 8 × 2\n  unittype     n\n  &lt;chr&gt;    &lt;int&gt;\n1 C        11419\n2 I           23\n3 IP         105\n4 P         5470\n5 R          420\n6 S            9\n7 SC        2377\n8 &lt;NA&gt;       610\n\n\nThis output tells us that there are quite a few observations with the NA category, meaning channel type was unknown or not recorded. Let’s edit the workflow above slightly, using drop_na() to remove any rows within a specified column (or columns) that have NA values:\n\n\nCode\ndata |&gt; \n  filter(species == \"Cutthroat trout\") |&gt; \n  drop_na(unittype) |&gt; \n  count(unittype)\n\n\n# A tibble: 7 × 2\n  unittype     n\n  &lt;chr&gt;    &lt;int&gt;\n1 C        11419\n2 I           23\n3 IP         105\n4 P         5470\n5 R          420\n6 S            9\n7 SC        2377\n\n\nThis returns just about the same data frame as the first method, but now with the NA category removed because it dropped any observations that were NA for unittype.\nFrom this we also observe that the highest Cutthroat trout abundances are found in cascade (C), pool (P), and side channel (SC) habitats.\nNow, our question expands beyond this one categorical variable (channel type) and we want to know if abundance is affected by both channel and and forest type (section). Here, our null hypothesis is that forest and channel type are independent. To test this, we use the chisq.test() to carry out a chi-square test, but first we have to reformat our data into a contingency table.\nA contingency table is in matrix format, where each cell is the frequency (in this case seen as abundance) of Cutthroat trout in each combination of categorical variables (forest type and channel unit). We can create a contingency table with the table() function. For this analysis, lets also keep just the 3 most abundant unit types for Cutthroat trout (C, P and SC).\n\n\nCode\n# First clean the dataset to create the contingency table from\ntrout_clean &lt;- data |&gt;\n  filter(species == \"Cutthroat trout\") |&gt;\n  filter(unittype %in% c(\"C\", \"P\", \"SC\")) |&gt;\n  drop_na(unittype, section)\n\ncont_table &lt;- table(trout_clean$section, trout_clean$unittype)\n\n\nTo execute the Chi-square test does not take that much code, but it is important to note that by default, chisq.test() assumes the null hypothesis is that all frequencies have equal probability. If you have different pre-conceived frequency probabilities for your data you have to define those within the chisq.test() function.\n\n\nCode\nchisq.test(cont_table)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  cont_table\nX-squared = 188.68, df = 2, p-value &lt; 2.2e-16\n\n\nLooking at these results, we see an extremely small p-valuetelling us there is a significant relationship between forest type and channel unit (i.e., we rejected our null hypothesis).\nLets look at the abundance distribution visually:\n\n\nCode\ntrout_clean  |&gt;  \n  count(unittype, section)  |&gt;  \n  ggpubr::ggbarplot(x = 'unittype', y = 'n', \n                    fill = 'section', \n                    palette = c(\"#00AFBB\", \"#E7B800\"),\n                    add = \"mean_se\")"
  },
  {
    "objectID": "index.html#t-test---compare-two-means",
    "href": "index.html#t-test---compare-two-means",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "t-test - Compare two means",
    "text": "t-test - Compare two means\nPrevious work has shown that forest harvesting practics can impact aquatic vertebrate biomass (Kaylor & Warren 2017). Using the and_vertebrates data set we can investigate this by comparing weight to forest type (clear cut or old growth). This involves a test to compare the means (average weight) among two groups (clear cut and old growth forests) using a t-test.\nLet’s focus on conducting this test for Cutthroat trout. We can use the same trout_clean data set we made earlier so long as we drop all NAs in weight_g. Once this is done, we can visualize the differences in weight among forest type with a boxplot:\n\n\nCode\ntrout_clean |&gt; \n  drop_na(weight_g) |&gt; \n  ggpubr::ggviolin(x = \"section\", \n                   y     = \"weight_g\", \n                   add   = \"boxplot\",\n                   color = \"section\",\n                   palette = c(\"#00AFBB\", \"#E7B800\")) \n\n\n\n\n\n\n\n\n\nWe don’t see too much of a difference based on this visual, but we need to conduct the statistical test to verify. Before we dive into the statistical t-test, we must check our assumptions!\nTest Assumptions: A t-test assumes the variance of each group is equal and the data are normally distributed.\nEqual Variance We can test for equal variances with the function var.test(), where the null hypothesis is that the variances are equal. In this step, we need two vectors of the weights in each separate forest section. You can use pull() to convert a single column of a data frame/tibble to a vector, and we want to do this for clear cut and old growth forests.\n\n\nCode\ncc_weight &lt;- trout_clean |&gt; \n  filter(section == \"CC\") |&gt; \n  pull(weight_g)\n\nog_weight &lt;- trout_clean |&gt; \n  filter(section == \"OG\") |&gt; \n  pull(weight_g)\n\nvar.test(cc_weight, og_weight)\n\n\n\n    F test to compare two variances\n\ndata:  cc_weight and og_weight\nF = 1.2889, num df = 6310, denom df = 5225, p-value &lt; 2.2e-16\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 1.223686 1.357398\nsample estimates:\nratio of variances \n          1.288892 \n\n\nThe results of this test suggests the variances are not equal. How do we know this? If you can’t remember, please refresh your memory of the null hypothesis for the variance test and how to interpret the p-value. - We know this because\n\n\n\n\n\n\nNote\n\n\n\nOne option for data with unequal variances is to use the non parametric Welch t-test, which does not assume equal variances. We will explore this test later.\n\n\nNormal Distribution A t-test mandates data with a normal distribtution. Here we can use a visual method to access the normality of the data:\n\n\nCode\nggpubr::ggarrange(ggpubr::gghistogram(cc_weight, main = \"Clear Cut\"), \n                  ggpubr::gghistogram(og_weight, main = \"Old Growth\"))\n\n\n\n\n\n\n\n\n\nWe can see from the histograms that the data are very right skewed. When we see a heavy right skew, we know a log transform can help normalize the data. Let’s check the variances like we did before using the log transformed values:\n\n\nCode\nvar.test(log(cc_weight), log(og_weight))\n\n\n\n    F test to compare two variances\n\ndata:  log(cc_weight) and log(og_weight)\nF = 1.0208, num df = 6310, denom df = 5225, p-value = 0.4374\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.9691443 1.0750427\nsample estimates:\nratio of variances \n          1.020787 \n\n\nNow we have a much higher p-value, indicating support for the null that the variances of log-transformed data are equal. So we can use the default t.test() test which assumes equal variances, but only on a log transformed weight variable.\nThe t.test() function takes in your dependent (in our case trout weight) and independent (forest type) variables as vectors. The order of the variables in the t.test() function is {dependent variable} ~ {independent variable}. We use the ~ to specify a model, telling the test we want to know if weight varies by forest section.\nRemember we also want to log transform the weight values and then specify that our variances are equal since we confirmed that with var.test() above, so the final t.test() call would be this:\n\n\nCode\nt.test(log(trout_clean$weight_g) ~ trout_clean$section, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  log(trout_clean$weight_g) by trout_clean$section\nt = 2.854, df = 11535, p-value = 0.004324\nalternative hypothesis: true difference in means between group CC and group OG is not equal to 0\n95 percent confidence interval:\n 0.02222425 0.11969560\nsample estimates:\nmean in group CC mean in group OG \n        1.457042         1.386082 \n\n\nThe output of this test gives us the test statistics, p-value, and the means for each of our forest groups. Given the p-value of 0.0043, we reject the null hypothesis (mean Cutthroat weight is the same in clear cut and old growth forest sections), and looking at our results - specifically the means - we can conclude that Cutthroat trout weight was observed to be significantly higher in clear cut forests compared to old growth forests. Remember that the mean weight values are log transformed and not the raw weight in grams. The relationship can still be interpreted the same, but you will want to report the means from the raw weight data.\nHow does this relate to the original hypothesis based on the graph we made at the beginning of this section?\nWelch Two Sample t-test\nAlternatively, instead of transforming our variable we can change the default t.test() argument by specifying var.equal = FALSE, which will then conduct a Welch t-test, which does not assume equal variances among groups.\n\n\nCode\nt.test(trout_clean$weight_g ~ trout_clean$section, var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  trout_clean$weight_g by trout_clean$section\nt = 4.5265, df = 11491, p-value = 6.056e-06\nalternative hypothesis: true difference in means between group CC and group OG is not equal to 0\n95 percent confidence interval:\n 0.4642016 1.1733126\nsample estimates:\nmean in group CC mean in group OG \n        8.988807         8.170050 \n\n\nWhile using a slightly different method, our conclusions are the same, finding that Cutthroat trout had significantly higher weights in clear cut forests than old growth.\n\nNote: In the t.test() function you can add paired = TRUE to conduct a paired t-test. These are for cases when the groups are ‘paired’ for each observation, meaning each group/treatment was applied to the same individual, such as experiments that test the impact of a treatment, with measurements before and after the experiment."
  },
  {
    "objectID": "index.html#correlation---assess-relationships",
    "href": "index.html#correlation---assess-relationships",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "Correlation - Assess relationships",
    "text": "Correlation - Assess relationships\nTo assess the relationship between two continuous variables, you use a correlation test, which is the cor.test() function. Correlation tests assess the presence of a significant relationship and the strength of each relationship (i.e., the correlation coefficient). There are multiple correlation methods you can use with this function but by default, it uses the Pearson correlation method which assumes your data are normally distributed and there is a linear relationship. If these assumptions are not met, you can use a Spearman Rank correlation test, a non-parametric test that is not sensitive to the variable distribution. To use this method, specify spearman for method.\nFor our and_vertebrates data set, we can test the relationship of length and weight. Let’s test the hypothesis that body length is positively correlated with weight, such that longer individuals will also weigh more, specifically looking at the Coastal Giant salamander.\nFirst let’s clean our data set to just include the Coastal giant salamander and remove missing values for length and weight.\n\n\nCode\nsally_clean &lt;- and_vertebrates |&gt; \n  filter(species == \"Coastal giant salamander\") |&gt; \n  drop_na(length_2_mm, weight_g)\n\n\nTesting Assumptions\nLet’s look at the distribution of these variables first:\n\n\nCode\nggarrange(gghistogram(sally_clean$length_2_mm, title = \"Length\"),\ngghistogram(sally_clean$weight_g, title = \"Weight\"))\n\n\n\n\n\n\n\n\n\nThey both look pretty skewed, therefore likely not normally distributed. We can statistically test if a variable fits a normal distribution with the shapiro.test() function, which is the Shapiro-Wilk normality text. However note that this function only runs for 5,000 observations or less, so we will test for normality for a sample of our sally_clean data set:\n\n\nCode\ns &lt;- sally_clean |&gt; \n  slice_sample(n = 5000) \n\nshapiro.test(s$length_2_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  s$length_2_mm\nW = 0.93103, p-value &lt; 2.2e-16\n\n\nCode\nshapiro.test(s$weight_g)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  s$weight_g\nW = 0.55832, p-value &lt; 2.2e-16\n\n\nThe null hypothesis of the Shapiro-Wilk normality test is that the variable is normally distributed, so a significant p-value less than 0.05 (as we see for both of our variables here) tells use that our data does not fit a normal distribution.\nTherefore we have two options as we did with our earlier t-test example: transform the variables or use the non-parametric test.\nVariable transformation\nLets try the first option by log transforming our variables, first viewing the log-transformed distribution for each variable.\n\n\nCode\nggarrange(\n gghistogram(log(sally_clean$length_2_mm), title = \"Length\"), \n gghistogram(log(sally_clean$weight_g), title = \"Weight\") \n)\n\n\n\n\n\n\n\n\n\nSince the log-transformed data look normally distributed (note that we can test using the Shapiro-Wilk normality test on the log-transformed data), we can use the Pearson’s correlation test (the default for cor.test()). All we need to add to the cor.test() argument is the two variables of our sally_clean data set we want to test a relationship for, and keep them log-transformed since those distributions looked closer to a normal distribution (visually at least).\n\n\nCode\ncor.test(log(sally_clean$length_2_mm), log(sally_clean$weight_g))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  log(sally_clean$length_2_mm) and log(sally_clean$weight_g)\nt = 402.85, df = 6229, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9804036 0.9822403\nsample estimates:\n      cor \n0.9813443 \n\n\nFrom these results we see a very small p-value, meaning there is a significant association between the two, and a correlation coefficient of 0.98, representing a strong, positive correlation.\nLet’s look at this correlation visually:\n\n\nCode\nsally_clean |&gt; \n  mutate(log_length = log(length_2_mm), log_weight = log(weight_g)) |&gt; \n  ggscatter(x = 'log_length', \n            y = 'log_weight', \n            alpha = .35,\n            add = \"loess\")\n\n\n\n\n\n\n\n\n\nSpearman Correlation Test\nLet’s now perform the correlation test again but keeping our raw data and instead specifying method = 'spearman', as the Spearman test is better for non-parametric and non-linear data sets.\n\n\nCode\ncor.test(sally_clean$length_2_mm, sally_clean$weight_g, method = \"spearman\")\n\n\n\n    Spearman's rank correlation rho\n\ndata:  sally_clean$length_2_mm and sally_clean$weight_g\nS = 819296957, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.9796802 \n\n\nThese results also represent a significant (p-value &lt; 2.2e-16), positive relationship between length and weight for the Coastal Giant salamander, with a very high correlation coefficient."
  },
  {
    "objectID": "index.html#exercises-part-1",
    "href": "index.html#exercises-part-1",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "Exercises: Part 1",
    "text": "Exercises: Part 1\nEach question requires you to carry out a statistical analysis to test some hypothesis related to the and_vertebrates data set. To answer each question fully:\n\nInclude the code you used to clean the data and conduct the appropriate statistical test. (Including the steps to assess and address your statistical test assumptions).\nReport the findings of your test in proper scientific format (with the p-value in parentheses).\n\n\n1. Conduct a chi-square test similar to the one carried out above, but test for a relationship between forest type (section) and channel unit (unittype) for Coastal giant salamander abundance. Keep all unittypes instead of filtering any like we did for the Cutthroat trout (10 pts.)\n\n\n\nCode\ndata |&gt; \n  filter(species == \"Coastal giant salamander\") |&gt; \n  drop_na(unittype) |&gt; \n  count(unittype)\n\n\n# A tibble: 6 × 2\n  unittype     n\n  &lt;chr&gt;    &lt;int&gt;\n1 C         7697\n2 IP          50\n3 P         1943\n4 R           72\n5 S            2\n6 SC        1994\n\n\nThis tibble can show us the distribution of obsercations based on the 6 locations taken for the data set, exemping any that were observed as NA to clean the data we are investigating for Coastal giant salamander abundance.\n\n\nCode\nGS_clean &lt;- data |&gt;\n  filter(species == \"Coastal giant salamander\") |&gt;\n  drop_na(unittype, section)\n\nGS_table &lt;- table(GS_clean$section, GS_clean$unittype)\n\n\nThis is the cleaned data code for reducing the amount of those found with N/A.\n\n\nCode\nchisq.test(cont_table)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  cont_table\nX-squared = 188.68, df = 2, p-value &lt; 2.2e-16\n\n\nWe can understand that the inital Chi-sqaured test indicated that there is a statistically significant relationship between location of the site and abundacne of Coastal giant salmanders.\n\n\nCode\nGS_clean  |&gt;  \n  count(unittype, section)  |&gt;  \n  ggpubr::ggbarplot(x = 'unittype', y = 'n', \n                    fill = 'section', \n                    palette = c(\"#00AFBB\", \"#E7B800\"),\n                    add = \"mean_se\") \n\n\n\n\n\n\n\n\n\nThe Chi-Sqaure Test shows that there is a significant difference between the forest type (section) and channel unit (unittype) for Coastal giant salamander abundance. As shown above in the table, there is a larger abundance of Coastal giant salamanders in cascades, pools, and side channel water bodies than the other three tested for (the most abudant in cascades) and an even split between clear cut growth and older growth confierious forests.\n2. Test the hypothesis that there is a significant difference in species biomass between clear cut and old growth forest types for the Coastal Giant salamander. (10 pts.)\n\n\n\nCode\nGS_clean |&gt; \n  drop_na(weight_g) |&gt; \n  ggpubr::ggviolin(x = \"section\", \n                   y     = \"weight_g\", \n                   add   = \"boxplot\",\n                   color = \"section\",\n                   palette = c(\"#00AFBB\", \"#E7B800\")) \n\n\n\n\n\n\n\n\n\nThe data represented in the histogram plot above, shows that there isn’t a realy difference between the Clear cut trees and old growth forests, indicating we need to clean the data further or add another indicator.\n\n\nCode\ncc_weight &lt;- GS_clean |&gt; \n  filter(section == \"CC\") |&gt; \n  pull(weight_g)\n\nog_weight &lt;- GS_clean |&gt; \n  filter(section == \"OG\") |&gt; \n  pull(weight_g)\n\nvar.test(cc_weight, og_weight)\n\n\n\n    F test to compare two variances\n\ndata:  cc_weight and og_weight\nF = 0.82901, num df = 3027, denom df = 3309, p-value = 1.439e-07\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.7732148 0.8889213\nsample estimates:\nratio of variances \n         0.8290065 \n\n\nThe results of this test suggests the variances are not equal. Because the ratio of variances is closer to 1 than 0, making the sample of this data selection of normal distribution.\n\n\nCode\nggpubr::ggarrange(ggpubr::gghistogram(cc_weight, main = \"Clear Cut\"), \n                  ggpubr::gghistogram(og_weight, main = \"Old Growth\"))\n\n\n\n\n\n\n\n\n\nThe data of CG salamander abundance is right-skewed in both the Clear cut and Old growth coniferous forests based on the sample data.\n\n\nCode\nvar.test(log(cc_weight), log(og_weight))\n\n\n\n    F test to compare two variances\n\ndata:  log(cc_weight) and log(og_weight)\nF = 0.90548, num df = 3027, denom df = 3309, p-value = 0.005299\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.8445382 0.9709179\nsample estimates:\nratio of variances \n         0.9054763 \n\n\nThe weight of the CG salamander is statistically significant to test, rejecting the null hypothesis saying that this data is normally distributed. (p-value = 0.005299).\n\n\nCode\nt.test(log(trout_clean$weight_g) ~ trout_clean$section, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  log(trout_clean$weight_g) by trout_clean$section\nt = 2.854, df = 11535, p-value = 0.004324\nalternative hypothesis: true difference in means between group CC and group OG is not equal to 0\n95 percent confidence interval:\n 0.02222425 0.11969560\nsample estimates:\nmean in group CC mean in group OG \n        1.457042         1.386082 \n\n\nCode\nt.test(trout_clean$weight_g ~ trout_clean$section, var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  trout_clean$weight_g by trout_clean$section\nt = 4.5265, df = 11491, p-value = 6.056e-06\nalternative hypothesis: true difference in means between group CC and group OG is not equal to 0\n95 percent confidence interval:\n 0.4642016 1.1733126\nsample estimates:\nmean in group CC mean in group OG \n        8.988807         8.170050 \n\n\nThe Two sample t-test shows that there is\n3. Test the correlation between body length (snout to fork length) and body mass for Cutthroat trout. (Hint: run ?and_vertebrates to find which length variable represents snout to fork length) (10 pts.)\n\n\nCode\n#?and_vertebrates # snout-fork length for trout -&gt; length_1_mm\n\n\n\n\nCode\ncut_clean &lt;- and_vertebrates |&gt; \n  filter(species == \"Cutthroat trout\") |&gt; \n  drop_na(length_1_mm, weight_g)\n\n\n\n\nCode\nggarrange(gghistogram(cut_clean$length_1_mm, title = \"Length\"),\ngghistogram(cut_clean$weight_g, title = \"Weight\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\nc &lt;- cut_clean |&gt; \n  slice_sample(n = 5000) \n\nshapiro.test(c$length_1_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  c$length_1_mm\nW = 0.93997, p-value &lt; 2.2e-16\n\n\nCode\nshapiro.test(c$weight_g)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  c$weight_g\nW = 0.77994, p-value &lt; 2.2e-16\n\n\n\n\nCode\nggarrange(\n gghistogram(log(cut_clean$length_1_mm), title = \"Length\"), \n gghistogram(log(cut_clean$weight_g), title = \"Weight\") \n)\n\n\n\n\n\n\n\n\n\n\n\nCode\ncor.test(log(cut_clean$length_1_mm), log(cut_clean$weight_g))\n\n\n\n    Pearson's product-moment correlation\n\ndata:  log(cut_clean$length_1_mm) and log(cut_clean$weight_g)\nt = 915.66, df = 12590, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9923125 0.9928295\nsample estimates:\n      cor \n0.9925755 \n\n\n\n\nCode\ncut_clean |&gt; \n  mutate(log_length = log(length_1_mm), log_weight = log(weight_g)) |&gt; \n  ggscatter(x = 'log_length', \n            y = 'log_weight', \n            alpha = .35,\n            add = \"loess\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ncor.test(cut_clean$length_1_mm, cut_clean$weight_g, method = \"spearman\")\n\n\n\n    Spearman's rank correlation rho\n\ndata:  cut_clean$length_1_mm and cut_clean$weight_g\nS = 2669679446, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.9919772 \n\n\nThese results also represent a significant, positive relationship between length and weight for the Cutthroat trout, with a very high correlation (rho)."
  },
  {
    "objectID": "index.html#explore-the-data-set",
    "href": "index.html#explore-the-data-set",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "Explore the Data set",
    "text": "Explore the Data set\nThis data set consists of Fiddler crab body size measured in salt marshes from Florida to Massachusetts during summer 2016 at Plum Island Ecosystem LTER.\n\n\nCode\nglimpse(pie_crab)\n\n\nRows: 392\nColumns: 9\n$ date          &lt;date&gt; 2016-07-24, 2016-07-24, 2016-07-24, 2016-07-24, 2016-07…\n$ latitude      &lt;dbl&gt; 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, …\n$ site          &lt;chr&gt; \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", …\n$ size          &lt;dbl&gt; 12.43, 14.18, 14.52, 12.94, 12.45, 12.99, 10.32, 11.19, …\n$ air_temp      &lt;dbl&gt; 21.792, 21.792, 21.792, 21.792, 21.792, 21.792, 21.792, …\n$ air_temp_sd   &lt;dbl&gt; 6.391, 6.391, 6.391, 6.391, 6.391, 6.391, 6.391, 6.391, …\n$ water_temp    &lt;dbl&gt; 24.502, 24.502, 24.502, 24.502, 24.502, 24.502, 24.502, …\n$ water_temp_sd &lt;dbl&gt; 6.121, 6.121, 6.121, 6.121, 6.121, 6.121, 6.121, 6.121, …\n$ name          &lt;chr&gt; \"Guana Tolomoto Matanzas NERR\", \"Guana Tolomoto Matanzas…\n\n\nCode\nvis_dat(pie_crab)\n\n\n\n\n\n\n\n\n\nLearn more about each variable:\nThe pie_crab data set, collected during the summer of 2016, aims to understand the differences of Fiddler crab (adult Minuca pugnax) body sizes as they are related to their local environments within the thirteen salt marshes from Florida to Massachusetts. Collected to measure how their difference in size related to the local temperature, water, and air data as understood from monitoring programs (i.e. LTER, NERR sites), nearby weather statuons, and ocean buoys. Since it is understood by the Bergmann’s rule that organisms located at higher latitudes are larger than those at lower latitudes, this data tests that ruling.\nWe have a continuous size variable (carapace width in mm), our dependent variable, and various predictor variables: site (categorical), latitude (continuous), air temperature (continuous) and water temperature (continuous).\nLet’s explore the sample size at each site and how many sites are in this data set\n\n\nCode\n# sample size per site\ncount(pie_crab, site)\n\n\n# A tibble: 13 × 2\n   site      n\n   &lt;chr&gt; &lt;int&gt;\n 1 BC       37\n 2 CC       27\n 3 CT       33\n 4 DB       30\n 5 GTM      28\n 6 JC       30\n 7 NB       29\n 8 NIB      30\n 9 PIE      28\n10 RC       25\n11 SI       30\n12 VCR      30\n13 ZI       35\n\n\nWe have 13 sites with ~30 individual male crabs measured at each site.\nLet’s also check the range of our continuous variables:"
  },
  {
    "objectID": "index.html#exercises-part-2",
    "href": "index.html#exercises-part-2",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "Exercises: Part 2",
    "text": "Exercises: Part 2\n\nAfter completing the ANOVA test (and post-hoc Tukey’s HSD) above to test for significant differences in crab size among 3 different sites: 1) Create a boxplot showing the carapace width for each site where sites are ordered by latitude and 2) report the findings of the statistical test as you would in a scientific paper. Include both the code to create the boxplot and an image of the figure. (10 pts.)"
  },
  {
    "objectID": "index.html#work",
    "href": "index.html#work",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "Work",
    "text": "Work\n\n\nCode\npie_crab |&gt; \n  ggboxplot(x = 'site', y = 'size', col = 'site') +\n  geom_jitter(size =.25) + \n  theme(legend.postition = \"none\")\n\n\n\n\n\n\n\n\n\nCode\nnorms &lt;- pie_crab |&gt; \n  nest(data = -site) |&gt;\n  mutate(Shapiro = map(data, ~ shapiro.test(.x$size)),\n         n = map_dbl(data, nrow),\n         glance_shapiro = map(Shapiro, broom::glance)) |&gt;\n  unnest(glance_shapiro)\n\nflextable::flextable(dplyr::select(norms, site, n, statistic, p.value)) |&gt;\n  flextable::set_caption(\"Shapiro-Wilk normality test for size at each site\")\n\n\nsitenstatisticp.valueGTM280.90078140.0119337484SI300.97053520.5539208550NIB300.97282970.6191340731ZI350.97445830.5765589900RC250.93150620.0941588802VCR300.94446820.1200262239DB300.95762710.2690631942JC300.96347540.3788327942CT330.92773650.0301785639NB290.96753670.4949587443CC270.93546590.0941803007BC370.88857210.0014402753PIE280.84893990.0008899392\n\n\nCode\nres_aov &lt;- aov(size ~ site, data = pie_crab)\n\ngghistogram(res_aov$residuals)\n\n\n\n\n\n\n\n\n\nCode\nshapiro.test(res_aov$residuals)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  res_aov$residuals\nW = 0.99708, p-value = 0.7122\n\n\nCode\nleveneTest(size ~ site, data = pie_crab)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value    Pr(&gt;F)    \ngroup  12  9.2268 1.151e-15 ***\n      379                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\n#perform Welch's ANOVA\noneway.test(size ~ site, data = pie_crab, var.equal = FALSE)\n\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  size and site\nF = 39.108, num df = 12.00, denom df = 145.79, p-value &lt; 2.2e-16\n\n\nCode\n# Filter a subset of the sites\npie_sites &lt;- pie_crab |&gt; \n  filter(site %in% c(\"GTM\", \"DB\", \"PIE\"))\n\n# Check for equal variance\nleveneTest(size ~ site, data = pie_sites)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  2   0.548 0.5802\n      83               \n\n\nCode\n# Note that the variances are equal (p = 0.5802), so we can proceed with the ANOVA\n\n# ANOVA for the data subset\npie_anova &lt;- aov(size ~ site, data = pie_sites)\n\n# View the ANOVA results \nsummary(pie_anova)\n\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)    \nsite         2  521.5  260.75   60.02 &lt;2e-16 ***\nResiduals   83  360.6    4.34                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nTukeyHSD(pie_anova)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = size ~ site, data = pie_sites)\n\n$site\n             diff       lwr       upr   p adj\nGTM-DB  -3.200786 -4.507850 -1.893722 3.0e-07\nPIE-DB   2.899929  1.592865  4.206992 2.9e-06\nPIE-GTM  6.100714  4.771306  7.430123 0.0e+00\n\n\n\n\n\nCode\nggboxplot(pie_anova, x = \"site\", y = \"size\", palette = \"jco\") +\n  geom_jitter(size =.25) + \n  theme(legend.postition = \"none\")\n\n\n\n\n\n\n\n\n\nTo understand the difference in crab sizes as they relate to their latitudinal location, we based our research following the Fiddler crab body size data set. With 13 sites that range in latitude from 30 degrees to 42 degrees and 13 different classes of sites, we aimed to understand the distribution within each group using an initial ANOVA test and Shapiro-Wilk normality test. With all the cases, their p-values were below 0.01, with an expection for BC and PIE, this means that the data fits within a normal distribution across grouping. During the Shapiro-WIlk normaily test, we founda residual with p-value of 0.71, accepting the null hypothesis that this data fits a normal distribution. Next using the Leven’s test to understand the equalily of variance across all groups, we confirmed that the data set we focused on was NOT equal. We then tested the response to a Welch ANOVA, specifying the variance was false, this proved a highly statistically significant corelation with our site’s mean is different from the others.\nTo understand further, we south out to use a Tukey’s HSD post-hoc test, to understand the pairwise comparisons of the 13 sites and their latitudinal significance to crab size. To simplify the statisical approach we focused on 3 sites; GTM, DB, and PIE, since they represent the wide breadth of latitudinal differences in the data. Using a 95% confidence interval with the Tukey, we found that there was a significant difference between GTM, DB, and PIE, as shown in the box plot represented above.\n\nConduct a simple linear regression for the effect of water_temp_sd (a measure reflecting annual variation in water temperature) on carapace width. Report your findings (include code and a sentence reporting the results) AND create a plot with a line of best fit. Include both the code to create the plot and an image of the figure. (10 pts).\n\n\n\nCode\npie_lm &lt;- lm(size ~ water_temp_sd, data = pie_crab)\n\n#view the results of the linear model\nsummary(pie_lm)\n\n\n\nCall:\nlm(formula = size ~ water_temp_sd, data = pie_crab)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.9428 -2.6948 -0.2145  2.6573  8.8070 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   13.93728    1.15338  12.084   &lt;2e-16 ***\nwater_temp_sd  0.09938    0.15716   0.632    0.528    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.506 on 390 degrees of freedom\nMultiple R-squared:  0.001024,  Adjusted R-squared:  -0.001537 \nF-statistic: 0.3999 on 1 and 390 DF,  p-value: 0.5275\n\n\nCode\npie_crab |&gt; \n  ggscatter(x = 'water_temp_sd', y = 'size', \n            alpha = .35, \n            add = \"reg.line\")\n\n\n\n\n\n\n\n\n\nThese results can depict that the size of the carapace of the crabs is not related to the temperature of the water as it varies between each location surveyed. Only part of the time did the size of the carapace aline wiht the regression line as represented in the figure above.\n\nConduct a multiple linear regression for the effects of latitude, air_temp_sd, and water_temp_sd on carapace width. First check for correlations among the three predictor variables (and report the correlation table) and second report your findings from the multiple linear regression (code and a sentence reporting the results). (10 pts.)\n\n\n\nCode\npie_crab |&gt; \n  dplyr::select(latitude, air_temp_sd, water_temp_sd) |&gt; \n  cor()\n\n\n                latitude air_temp_sd water_temp_sd\nlatitude      1.00000000   0.7932130    0.04188273\nair_temp_sd   0.79321301   1.0000000    0.40970338\nwater_temp_sd 0.04188273   0.4097034    1.00000000\n\n\nThe correlation table understanding the relationship between latitude, air temp sd, water temp sd have correlation between air temp and latitude, but water temp sd is not correlated to thier air temp or latitude since the correlation coefficient is less than 0.7.\n\n\nCode\npie_mlm &lt;- lm(size ~ latitude + air_temp_sd + water_temp_sd, data = pie_crab)\n\nsummary(pie_mlm)\n\n\n\nCall:\nlm(formula = size ~ latitude + air_temp_sd + water_temp_sd, data = pie_crab)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.7515 -1.8897  0.0506  1.9301  6.6746 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -3.96880    1.54818  -2.564   0.0107 *  \nlatitude       0.55940    0.06413   8.723   &lt;2e-16 ***\nair_temp_sd   -0.41713    0.30559  -1.365   0.1730    \nwater_temp_sd  0.15927    0.16174   0.985   0.3254    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.832 on 388 degrees of freedom\nMultiple R-squared:  0.3516,    Adjusted R-squared:  0.3466 \nF-statistic: 70.13 on 3 and 388 DF,  p-value: &lt; 2.2e-16\n\n\nThe multiple linear regression model for the comparison of carapase size on latitude, air temp sd, water temp sd, shows a statistically significant trend indicating there is an impact based on the latitude (p-value &lt; 2.2 e-16) of the crab and the size of it’s carapace in width (rejecting the null hypothesis), however, both air temperautre (p-value = 0.1730) and water temperature sd (p-value = 0.3254) prove to have no statistical significance on the size of a crabs carapace (accepting the null hypothesis)."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThanks to the developers of lterdatasampler for providing the data set and vignettes that helped guide the creation of this lesson plan."
  },
  {
    "objectID": "index.html#citations",
    "href": "index.html#citations",
    "title": "ESS330 Lab 4: LTER Network Data",
    "section": "Citations",
    "text": "Citations\n\nJohnson, D. 2019. Fiddler crab body size in salt marshes from Florida to Massachusetts, USA at PIE and VCR LTER and NOAA NERR sites during summer 2016. ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/4c27d2e778d3325d3830a5142e3839bb (Accessed 2021-05-27).\nJohnson DS, Crowley C, Longmire K, Nelson J, Williams B, Wittyngham S. The fiddler crab, Minuca pugnax, follows Bergmann’s rule. Ecol Evol. 2019;00:1–9. https://doi.org/10.1002/ece3.5883\n\nData Source: Gregory, S.V. and I. Arismendi. 2020. Aquatic Vertebrate Population Study in Mack Creek, Andrews Experimental Forest, 1987 to present ver 14. Environmental Data Initiative. https://doi.org/10.6073/pasta/7c78d662e847cdbe33584add8f809165\nKaylor, M.J. and D.R. Warren. 2017. Linking riparian shade and the legacies of forest management to fish and vertebrate biomass in forested streams. Ecosphere 8(6). https://doi.org/10.1002/ecs2.1845"
  }
]